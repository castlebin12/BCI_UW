```
The Classification Problem

Some random images are displayed.
So, How do we build a classifier that can distinguish between faces & other objects?
```
![](http://geekresearchlab.net/coursera/neuro/cll-1.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-2.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-3.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-4.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-5.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-6.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-7.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-8.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-9.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-10.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-11.jpg)
```
Question:
Which of the following could you use to minimize the error function with respect to W & w? 
(Hint: Where have we seen the use of gradients before with respect to optimization?)
Answer:
Gradient descent
Explanation:
We used gradient ascent for maximizing the log posterior function in the Sparse Coding and Predictive Coding lecture. 
Here we use gradient descent for minimizing a function.
```
![](http://geekresearchlab.net/coursera/neuro/cll-12.jpg)<br><br>
![](http://geekresearchlab.net/coursera/neuro/cll-13.jpg)
